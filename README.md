# Bachelor-Thesis
I worked with 2 highly imbalanced datasets, applied various combinations to handle imbalance, optimized models, and analyzed feature importance. This resulted in a 4x improvement in prediction accuracy!  

ðŸ”¹ Tech Stack: Python, Power BI, BPMN.  
ðŸ”¹ Imbalance Handling: SMOTE, Hybrid Methods, Oversampling, Undersampling, Internal Parameters.  
ðŸ”¹ Hyperparameter Tuning: Random Search, Grid Search.  
ðŸ”¹ Feature Importance & Interpretation: Model Coefficients, Permutation Importance, Spearman Correlation, SHAP, Odds Ratios.
ðŸ”¹ Models: Logistic Regression, XGBoost Classifier, Random Forest, LGBM Classifier.
